# KNN

## 简介

KNN(K nearest neighbor)即是K最临近算法。如何给一个样本分类？只需检查和该样本最近的K个已知样本的分类，统计这K个样本的类别，拥有最多样本的类别，即为算法预测新样本的类别。

## 距离如何测算？

根据实际情况选择，可以选择欧式距离，曼哈顿距离等。

## 如何选择K？

可以通过交叉验证的方式找到一个最好的K来使用。

## 总结

1. KNN是一个极其简单的算法
2. 比较适合应用低维空间
3. KNN在训练过程中实质上不需要做任何事情，所以训练本身不产生任何时间上的消耗
4. 然而，KNN在预测过程中需要循环所有的样本数据，复杂度线性依赖与样本个数，这成为KNN应用在大数据上时的瓶颈